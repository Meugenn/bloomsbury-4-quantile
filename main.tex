\documentclass[12pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{xcolor}
\usepackage{authblk}
\usepackage{setspace}

% Configure hyperref
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
    citecolor=blue,
}

% Title and authors
\title{\textbf{Quantifying False Precision: Expert Consensus vs. Quantile Machine Learning in High-End Art Valuation}\\
\vspace{0.3cm}
\large{A Replication Study on Sotheby's Auction Data (2020--2025)}}

\author{Bloomsbury Tech}
\date{February 2026}

\begin{document}

\maketitle

\begin{abstract}
\noindent
We study false precision in expert art valuations using the complete population of Sotheby's lots (2020--2025) meeting our inclusion criteria: sold with realized prices, expert pre-sale estimates, physical dimensions, and medium metadata ($n=13{,}609$ lots). Through 10-fold cross-validation of LightGBM quantile regression models, we demonstrate that expert pre-sale estimates capture only \textbf{29.4\% $\pm$ 1.5\%} of realized hammer prices, while our machine learning models achieve \textbf{72.0\% $\pm$ 1.5\%} coverage---an improvement of 42.6 percentage points. Experts employ artificially narrow valuation ranges (median spread: 35.0\% of asset value) that exhibit classic \textit{false precision}, whereas ML models use appropriately calibrated uncertainty ranges (median spread: 882.8\%) that are 25.2$\times$ wider. Both methods demonstrate minimal bias (expert: $-4.1\%$, model: $+0.3\%$), confirming that the primary deficiency lies in range calibration rather than point estimation.

\vspace{0.5cm}
\noindent
\textbf {}
\end{abstract}

\onehalfspacing

\section{Introduction}

The valuation of high-value artworks presents a unique challenge in asset pricing. Unlike traditional financial instruments with observable cash flows, art derives value from subjective aesthetic merit, provenance, artist reputation, and cultural significance. Auction houses employ domain experts to provide pre-sale estimates, typically expressed as a range (e.g., \$50,000--\$70,000), intended to guide prospective bidders and establish reserve prices.

\subsection{The False Precision Hypothesis}

Our research has challenged the reliability of expert estimates, suggesting that they suffer from \textit{false precision--the} tendency to express unwarranted confidence through artificially narrow uncertainty ranges. This phenomenon has significant implications:

\begin{itemize}
    \item \textbf{Economic efficiency:} Misleading estimates distort bidder behavior and price discovery
    \item \textbf{Risk management:} Collectors and institutions make suboptimal portfolio decisions
    \item \textbf{Market transparency:} False confidence erodes trust in auction mechanisms
\end{itemize}

\subsection{Research Objectives}

This study replicates the seminal work on false precision using an independent dataset of 13,609 Sotheby's lots (2020--2025) and advanced cross-validation methodology. Our specific aims are as follows:

\begin{enumerate}
    \item Measure the \textit{coverage probability} of expert estimates vs. ML quantile models
    \item Quantify the \textit{spread efficiency} of valuation ranges
    \item Assess \textit{systematic bias} in point predictions
    \item Validate findings through rigorous 10-fold cross-validation
\end{enumerate}

\section{Methodology}

\subsection{Dataset}

\textbf{Source:} Sotheby's auction database (ClickHouse)\\
\textbf{Period:} January 2020 -- December 2025\\
\textbf{Population:} $n = 13{,}609$ lots (complete qualifying population, not a sample)\\
\textbf{Inclusion Criteria:}
\begin{itemize}
    \item \texttt{is\_sold = 1} (only realized transactions with hammer prices)
    \item Expert pre-sale estimates available (both \texttt{estimate\_low} and \texttt{estimate\_high})
    \item Physical dimensions recorded (height, width, surface area)
    \item Medium and artist metadata present
\end{itemize}

\noindent
\textbf{Note:} This represents \textit{all} Sotheby's lots from 2020--2025 meeting these criteria, not a random sample. Lots without estimates or dimensions are excluded as they cannot be evaluated for coverage probability.

\subsection{Feature Engineering}

We construct 85 features following established hedonic pricing literature:

\paragraph{Continuous Features:}
\begin{itemize}
    \item $\log(\text{surface area})$ and $[\log(\text{surface area})]^2$
    \item Artwork age: $\text{sale year} - \text{creation year}$
    \item Artist age at creation: $\text{creation year} - \text{birth year}$
    \item Number of bids (median-imputed for missing values)
\end{itemize}

\paragraph{Categorical Features (one-hot encoded):}
\begin{itemize}
    \item \textbf{Medium} (top 15, else ``other'')
    \item \textbf{Support} (top 5, else ``other'')
    \item \textbf{Artist name} (top 50 by lot count, else ``other'')
    \item \textbf{Location} (London, New York, Hong Kong, other)
    \item \textbf{Sale year} (2020--2025 as categorical)
\end{itemize}

\paragraph{Binary Flags:}
\begin{itemize}
    \item Artist deceased (vital status)
    \item Q4 sale (fourth quarter indicator)
    \item Rare artist flag
\end{itemize}

All categorical feature names are sanitized to remove special characters incompatible with LightGBM's JSON parser.

\subsection{Quantile Regression Models}

We train three separate LightGBM models targeting different quantiles:

\begin{equation}
\hat{q}_\alpha(\mathbf{x}) = \arg\min_{\hat{q}} \mathbb{E}\left[\rho_\alpha\left(y - \hat{q}(\mathbf{x})\right)\right]
\end{equation}

where $\rho_\alpha(u) = u(\alpha - \mathbb{1}_{u < 0})$ is the pinball loss function, and $\alpha \in \{0.10, 0.50, 0.90\}$.

\paragraph{Hyperparameters:}
\begin{verbatim}
objective:      'quantile'
alpha:          0.10, 0.50, 0.90
n_estimators:   1000
learning_rate:  0.05
num_leaves:     31
random_state:   42
\end{verbatim}

\paragraph{Monotonicity Enforcement:}
Independent quantile models may violate $\hat{q}_{0.10} \leq \hat{q}_{0.50} \leq \hat{q}_{0.90}$. We enforce ordering via:
\begin{align}
\tilde{q}_{0.50}(\mathbf{x}) &= \max\{\hat{q}_{0.10}(\mathbf{x}), \hat{q}_{0.50}(\mathbf{x})\} \\
\tilde{q}_{0.90}(\mathbf{x}) &= \max\{\tilde{q}_{0.50}(\mathbf{x}), \hat{q}_{0.90}(\mathbf{x})\}
\end{align}

Empirically, violations occurred in $\sim$14 predictions per fold ($<1\%$ of test samples).

\subsection{Cross-Validation Strategy}

To ensure robust performance estimates, we employ \textbf{10-fold stratified cross-validation}:

\begin{itemize}
    \item Data shuffled with fixed random seed (42)
    \item Each fold: 90\% training (12,248 lots), 10\% testing (1,361 lots)
    \item Total trained models: $3 \text{ quantiles} \times 10 \text{ folds} = 30$
    \item Every lot was tested exactly once
\end{itemize}

This approach eliminates variance from single train/test splits and provides confidence intervals for all metrics.

\subsection{Evaluation Metrics}

\paragraph{Coverage Probability:}
\begin{equation}
\text{Coverage} = \mathbb{P}\left(\hat{q}_{0.10}(\mathbf{x}) \leq y \leq \hat{q}_{0.90}(\mathbf{x})\right)
\end{equation}

For experts, $[\hat{q}_{0.10}, \hat{q}_{0.90}]$ is replaced by $[\text{estimate\_low}, \text{estimate\_high}]$.

\paragraph{Relative Spread:}
\begin{equation}
\text{Spread} = \frac{\hat{q}_{0.90}(\mathbf{x}) - \hat{q}_{0.10}(\mathbf{x})}{y} \times 100\%
\end{equation}

For log-space model predictions:
\begin{equation}
\text{Spread}_{\text{model}} = \left[\exp\left(\hat{q}_{0.90} - \hat{q}_{0.10}\right) - 1\right] \times 100\%
\end{equation}

\paragraph{Bias:}
\begin{equation}
\text{Bias} = \text{median}\left(\frac{\hat{q}_{0.50}(\mathbf{x}) - y}{y}\right) \times 100\%
\end{equation}

\section{Results}

\subsection{Coverage Probability}

Table~\ref{tab:coverage} summarizes coverage rates across 10 folds.

\begin{table}[H]
\centering
\caption{Coverage probability by fold (percentage of realized prices within predicted range)}
\label{tab:coverage}
\begin{tabular}{@{}ccc@{}}
\toprule
\textbf{Fold} & \textbf{Expert Consensus} & \textbf{Quantile Model} \\ \midrule
1  & 27.9\% & 69.5\% \\
2  & 28.6\% & 70.6\% \\
3  & 29.8\% & 72.7\% \\
4  & 28.0\% & 72.4\% \\
5  & 32.4\% & 72.4\% \\
6  & 29.8\% & 70.4\% \\
7  & 30.1\% & 74.7\% \\
8  & 28.1\% & 73.1\% \\
9  & 31.2\% & 73.3\% \\
10 & 27.9\% & 70.8\% \\ \midrule
\textbf{Mean} & \textbf{29.4\%} & \textbf{72.0\%} \\
\textbf{Std}  & \textbf{1.5\%}  & \textbf{1.5\%} \\ \bottomrule
\end{tabular}
\end{table}

\noindent
\textbf{Key Finding:} ML models achieve 2.45$\times$ better coverage (72.0\% vs. 29.4\%), missing only 28\% of realized prices compared to experts' 71\%.

\subsection{Spread Analysis}

Table~\ref{tab:spread} reports relative spread magnitudes.

\begin{table}[H]
\centering
\caption{Median spread as percentage of asset value}
\label{tab:spread}
\begin{tabular}{@{}ccc@{}}
\toprule
\textbf{Fold} & \textbf{Expert Spread} & \textbf{Model Spread} \\ \midrule
1  & 35.7\% & 872.7\% \\
2  & 36.0\% & 836.7\% \\
3  & 35.3\% & 913.2\% \\
4  & 35.0\% & 874.1\% \\
5  & 34.4\% & 920.6\% \\
6  & 35.3\% & 866.8\% \\
7  & 35.4\% & 902.2\% \\
8  & 33.7\% & 877.1\% \\
9  & 35.6\% & 929.5\% \\
10 & 33.9\% & 835.0\% \\ \midrule
\textbf{Mean} & \textbf{35.0\%} & \textbf{882.8\%} \\
\textbf{Std}  & \textbf{0.7\%}  & \textbf{31.3\%} \\ \bottomrule
\end{tabular}
\end{table}

\noindent
\textbf{Key Finding:} To achieve 2.45$\times$ better coverage, ML models employ spreads that are \textbf{25.2$\times$ wider} than expert ranges. Expert spreads are remarkably consistent ($\sigma = 0.7\%$), suggesting institutional guidelines rather than genuine uncertainty quantification.

\subsection{Bias}

Both methods exhibit minimal systematic bias (Table~\ref{tab:bias}).

\begin{table}[H]
\centering
\caption{Systematic bias in midpoint predictions}
\label{tab:bias}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Method} & \textbf{Mean Bias} & \textbf{Std Dev} \\ \midrule
Expert Consensus & $-4.1\%$ & $1.5\%$ \\
Quantile Model   & $+0.3\%$ & $1.2\%$ \\ \bottomrule
\end{tabular}
\end{table}

\noindent
\textbf{Key Finding:} Experts slightly \textit{underestimate} by 4.1\%, while ML models are nearly unbiased ($+0.3\%$). This suggests the primary deficiency in expert estimates is \textit{range calibration}, not point prediction.


\section{Discussion}

\subsection{Why Expert Estimates Underperform}

\paragraph{Cognitive Biases:}
\begin{itemize}
    \item \textbf{Anchoring:} Experts anchor to historical comparables without adjusting for tail risk
    \item \textbf{Overconfidence:} Human forecasters systematically underestimate uncertainty \cite{kahneman1973}
    \item \textbf{Availability heuristic:} Recent sales bias range construction
\end{itemize}

\paragraph{Institutional Constraints:}
\begin{itemize}
    \item \textbf{Reputational risk:} Wide ranges may signal incompetence
    \item \textbf{Marketing pressure:} Auction houses prefer narrow ``confident'' estimates to attract consignors
    \item \textbf{Strategic behavior:} Estimates influence reserve prices and buyer psychology
\end{itemize}

\subsection{ML Model Advantages}

\paragraph{Data-Driven Calibration:}
Quantile regression \textit{learns} uncertainty directly from historical price distributions, adaptively widening ranges for:
\begin{itemize}
    \item Rare artists (limited comparables)
    \item Extreme sizes (tail behavior)
    \item Volatile time periods (post-2020 market)
\end{itemize}

\paragraph{No Incentive Misalignment:}
Unlike human experts, ML models face no reputational or commercial pressure to appear confident.

\subsection{Implications}

\paragraph{For Collectors:}
\begin{itemize}
    \item Treat expert estimates as \textit{marketing ranges}, not risk assessments
    \item Use ML predictions for insurance valuations and portfolio planning
    \item Wide model spreads are \textit{informative}, not a modeling failure
\end{itemize}

\paragraph{For Auction Houses:}
\begin{itemize}
    \item Consider publishing probabilistic ranges (e.g., 80\% prediction intervals)
    \item Acknowledge uncertainty to build trust with sophisticated clients
    \item Use ML internally for reserve pricing and risk management
\end{itemize}

\paragraph{For Researchers:}
\begin{itemize}
    \item Art market uncertainty is systematically underestimated in practice
    \item False precision likely extends to other illiquid asset classes (real estate, collectibles)
    \item Future work: incorporate provenance, condition reports, and exhibition history
\end{itemize}

\subsection{Robustness of Cross-Validation}

The remarkably low variance across folds (coverage std: $\pm$1.5\%, expert spread std: 0.7\%) demonstrates that our findings are \textit{not} artifacts of a particular train/test split. Both expert underperformance and ML superiority are \textbf{highly consistent} across all data partitions.

\section{Limitations}

\begin{enumerate}
    \item \textbf{Single Auction House:} Results specific to Sotheby's; Christie's and Phillips may differ
    \item \textbf{Post-2020 Only:} Limited to recent COVID-era market with heightened volatility
    \item \textbf{Feature Set:} Missing provenance, exhibition history, and condition reports
    \item \textbf{Distribution Shift:} Models trained on 2020--2025 may not generalize to future markets
    \item \textbf{Survivorship Bias:} Only sold lots analyzed; unsold items excluded
\end{enumerate}

\section{Conclusion}

This study provides rigorous empirical validation of the false precision hypothesis in expert art valuations. Using 10-fold cross-validation on 13,609 Sotheby's lots, we demonstrate that expert pre-sale estimates capture only 29.4\% of realized prices---missing more than 7 out of 10 sales. In contrast, LightGBM quantile regression models achieve 72.0\% coverage by employing spreads 25 times wider than expert ranges.

Critically, both methods exhibit minimal bias ($<5\%$), confirming that experts' deficiency lies in \textit{uncertainty quantification}, not point estimation. The consistency of our findings across all cross-validation folds (std: $\pm$1.5\%) and alignment with the original paper's qualitative pattern suggest that false precision is a \textbf{systemic phenomenon} in high-value art markets.

As the art market increasingly attracts institutional investors and algorithmic traders, the need for rigorous uncertainty quantification becomes paramount. Our results suggest that machine learning models can provide the probabilistic forecasts necessary for modern portfolio management, risk assessment, and transparent price discovery.

\section*{Acknowledgments}

We thank the developers of LightGBM, pandas, and scikit-learn for providing open-source tools that enabled this research.

\section*{Data Availability}

All code, trained models, and aggregated results are available at: \\
\url{https://github.com/maynard-research/art-valuation}

Individual lot-level data cannot be shared due to commercial licensing restrictions.

\begin{thebibliography}{9}

\bibitem{kahneman1973}
Kahneman, D., \& Tversky, A. (1973).
On the psychology of prediction.
\textit{Psychological Review}, 80(4), 237--251.

\bibitem{koenker2001}
Koenker, R. (2001).
Quantile regression.
\textit{Journal of Economic Perspectives}, 15(4), 143--156.

\bibitem{ke2017}
Ke, G., Meng, Q., Finley, T., Wang, T., Chen, W., Ma, W., ... \& Liu, T. Y. (2017).
LightGBM: A highly efficient gradient boosting decision tree.
\textit{Advances in Neural Information Processing Systems}, 30.

\bibitem{rosen1974}
Rosen, S. (1974).
Hedonic prices and implicit markets: product differentiation in pure competition.
\textit{Journal of Political Economy}, 82(1), 34--55.

\bibitem{ashenfelter2003}
Ashenfelter, O., \& Graddy, K. (2003).
Auctions and the price of art.
\textit{Journal of Economic Literature}, 41(3), 763--787.

\bibitem{mei2002}
Mei, J., \& Moses, M. (2002).
Art as an investment and the underperformance of masterpieces.
\textit{American Economic Review}, 92(5), 1656--1668.

\bibitem{maddala1983}
Maddala, G. S. (1983).
\textit{Limited-dependent and qualitative variables in econometrics}.
Cambridge University Press.

\bibitem{breiman2001}
Breiman, L. (2001).
Random forests.
\textit{Machine Learning}, 45(1), 5--32.

\bibitem{gneiting2007}
Gneiting, T., \& Raftery, A. E. (2007).
Strictly proper scoring rules, prediction, and estimation.
\textit{Journal of the American Statistical Association}, 102(477), 359--378.

\end{thebibliography}

\clearpage

\section*{Appendices}

\subsection*{A. Visualization: Coverage Comparison}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{../output/visualizations/coverage_comparison.png}
\caption{Coverage probability comparison with 10-fold cross-validation error bars. The ML quantile model achieves 72.0\% $\pm$ 1.5\% coverage compared to expert consensus at 29.4\% $\pm$ 1.5\%, representing a 42.6 percentage point improvement.}
\label{fig:coverage}
\end{figure}

\subsection*{B. Visualization: Spread Distributions}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{../output/visualizations/efficiency_showdown.png}
\caption{Violin plot comparing spread distributions. Expert spreads cluster tightly around 35\% (median), while ML model spreads center at 883\% with substantial variation reflecting artwork-specific uncertainty. The 25$\times$ difference demonstrates that experts use artificially narrow ranges.}
\label{fig:spreads}
\end{figure}

\subsection*{C. Feature Importance (Example from Fold 1)}

\begin{table}[H]
\centering
\caption{Top 10 features by gain (50th percentile model, Fold 1)}
\begin{tabular}{@{}lc@{}}
\toprule
\textbf{Feature} & \textbf{Importance} \\ \midrule
log\_surface\_area & 0.324 \\
artist\_cat\_Basquiat & 0.152 \\
artist\_cat\_Hockney & 0.089 \\
medium\_cat\_oil\_on\_canvas & 0.067 \\
sale\_year\_cat\_2024 & 0.053 \\
location\_cat\_New\_York & 0.041 \\
artwork\_age & 0.039 \\
log\_surface\_area\_squared & 0.028 \\
num\_bids & 0.024 \\
artist\_deceased & 0.019 \\ \bottomrule
\end{tabular}
\end{table}

\subsection*{D. Reproducibility Checklist}

\begin{itemize}
    \item[$\checkmark$] Random seed fixed (42)
    \item[$\checkmark$] All hyperparameters documented
    \item[$\checkmark$] 10-fold CV ensures every lot tested exactly once
    \item[$\checkmark$] Feature engineering fully specified
    \item[$\checkmark$] Code available at GitHub repository
    \item[$\checkmark$] Results aggregated across all folds (no cherry-picking)
\end{itemize}

\end{document}
